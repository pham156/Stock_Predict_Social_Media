{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84361319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b052d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_yahoo_news_api(ticker, count=20):\n",
    "    url = (\n",
    "        f\"https://query1.finance.yahoo.com/v1/finance/search?\"\n",
    "        f\"q={ticker}&newsCount={count}&quotesCount=0\"\n",
    "    )\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    r = requests.get(url, headers=headers).json()\n",
    "\n",
    "    if \"news\" not in r:\n",
    "        return pd.DataFrame()  # no news found\n",
    "\n",
    "    rows = []\n",
    "    for item in r[\"news\"]:\n",
    "        try:\n",
    "            title = item.get(\"title\")\n",
    "            link = item.get(\"link\")\n",
    "            publisher = item.get(\"publisher\")\n",
    "            ts = item.get(\"providerPublishTime\")\n",
    "            dt = datetime.utcfromtimestamp(ts)\n",
    "\n",
    "            rows.append({\n",
    "                \"ticker\": ticker,\n",
    "                \"title\": title,\n",
    "                \"publisher\": publisher,\n",
    "                \"datetime\": dt,\n",
    "                \"url\": link,\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68212290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker                                              title       publisher  \\\n",
      "0   AAPL  Winning Stocks Keep Winning, And That’s What i...   24/7 Wall St.   \n",
      "1   AAPL  Could Nvidia Become the First $10 Trillion Com...     Motley Fool   \n",
      "2   AAPL  Meta (META) Stock Pops Following Metaverse Cut...   24/7 Wall St.   \n",
      "3   AAPL           Apple Is Richer Than All but 4 Countries  GOBankingRates   \n",
      "4   AAPL  Corporate America is scrambling to hire energy...   Yahoo Finance   \n",
      "5   AAPL  Not 'very hawkish at all': Wall Street optimis...   Yahoo Finance   \n",
      "6   AAPL  The Smartest Mining Stock to Buy With $100 Rig...     Motley Fool   \n",
      "7   AAPL  Prediction: This AI Stock Could Lead the Marke...     Motley Fool   \n",
      "8   AAPL  Investor Who Reached $10K/Month in Dividend In...        Benzinga   \n",
      "9   AAPL  2 Stocks That Turned $1,000 Into $1 Million (o...     Motley Fool   \n",
      "\n",
      "             datetime                                                url  \n",
      "0 2025-12-14 19:22:02  https://finance.yahoo.com/m/2b39ce9f-5c40-3e98...  \n",
      "1 2025-12-14 18:35:00  https://finance.yahoo.com/m/7f9488dd-7a48-345d...  \n",
      "2 2025-12-14 17:12:41  https://finance.yahoo.com/m/10ef226e-55e0-3460...  \n",
      "3 2025-12-14 16:45:23  https://finance.yahoo.com/news/apple-richer-4-...  \n",
      "4 2025-12-14 16:00:51  https://finance.yahoo.com/news/corporate-ameri...  \n",
      "5 2025-12-14 14:30:11  https://finance.yahoo.com/news/not-very-hawkis...  \n",
      "6 2025-12-14 13:05:00  https://finance.yahoo.com/m/21f7d080-35ce-31a8...  \n",
      "7 2025-12-14 06:53:00  https://finance.yahoo.com/m/d20eb998-9faf-30fa...  \n",
      "8 2025-12-13 21:01:01  https://finance.yahoo.com/news/investor-reache...  \n",
      "9 2025-12-13 19:25:00  https://finance.yahoo.com/m/fb2058fa-dce1-3a5a...  \n"
     ]
    }
   ],
   "source": [
    "df_news = fetch_yahoo_news_api(\"AAPL\", 20)\n",
    "print(df_news.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b952e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = fetch_yahoo_news_api(\"AAPL\")\n",
    "df_news[\"date\"] = df_news[\"datetime\"].dt.date\n",
    "news_by_day = df_news.groupby(\"date\")[\"title\"].apply(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "392ccc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2025-12-02    [Apple's 6 straight records, bitcoin recovery:...\n",
       "2025-12-03    [Apple’s AI Troubles Are Fading. Just Look at ...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80998185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2025-12-02    8\n",
      "2025-12-03    2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_counts = df_news['date'].value_counts().sort_index()\n",
    "print(news_counts)\n",
    "news_counts.plot(kind='bar', figsize=(12,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b94cc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "      <th>datetime</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ticker, title, publisher, datetime, url, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news[df_news['url'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27dd56fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publisher\n",
       "Barrons.com            3\n",
       "Yahoo Finance Video    2\n",
       "Investopedia           1\n",
       "Simply Wall St.        1\n",
       "MT Newswires           1\n",
       "Motley Fool            1\n",
       "Zacks                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['publisher'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82777b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def embed_day_articles(titles, ticker):\n",
    "    vectors = []\n",
    "    for title in titles:\n",
    "        v = generate_embedding(title, ticker)\n",
    "        if v is not None:\n",
    "            vectors.append(v)\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(8)\n",
    "    return np.mean(vectors, axis=0)     # aggregate daily sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38577070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnews import GNews\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_gnews(ticker, start_date, end_date):\n",
    "    google = GNews(\n",
    "        language='en',\n",
    "        country='US',\n",
    "        max_results=100  # IMPORTANT: must be <= 100 for date filtering to work\n",
    "    )\n",
    "\n",
    "    # Set date filter\n",
    "    google.start_date = pd.to_datetime(start_date).to_pydatetime()\n",
    "    google.end_date = pd.to_datetime(end_date).to_pydatetime()\n",
    "\n",
    "    # FIX: remove spaces from query\n",
    "    query = f\"{ticker} stock\".replace(\" \", \"+\")\n",
    "\n",
    "    articles = google.get_news(query)\n",
    "    rows = []\n",
    "\n",
    "    for a in articles:\n",
    "        try:\n",
    "            dt = pd.to_datetime(a[\"published date\"])\n",
    "        except:\n",
    "            dt = None\n",
    "\n",
    "        rows.append({\n",
    "            \"ticker\": ticker,\n",
    "            \"title\": a[\"title\"],\n",
    "            \"publisher\": a[\"publisher\"][\"title\"] if \"publisher\" in a else \"\",\n",
    "            \"datetime\": dt,\n",
    "            \"url\": a[\"url\"]\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sort_values(\"datetime\", ascending=False).reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d34e480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker                                              title  \\\n",
      "0   AAPL  Apple (APPL) Stock Eyes $1T in Gains, Analyst ...   \n",
      "1   AAPL  4 Reasons to Buy Apple Stock Like There's No T...   \n",
      "2   AAPL  Apple (APPL) Stock Eyes $1T in Gains, Analyst ...   \n",
      "3   AAPL  Warren Buffett Has Been Dumping Apple Stock fo...   \n",
      "4   AAPL  Apple Inc (AAPL) DCF Valuation: Is The Stock U...   \n",
      "5   AAPL  Apple Inc. (AAPL): Developing Advanced LLM Sir...   \n",
      "6   AAPL  Apple (AAPL) Surged After Solid Earnings Repor...   \n",
      "7   AAPL  Here is Why Warren Buffett Sold AAPL Stock - Y...   \n",
      "8   AAPL  Is Apple Inc. (AAPL) Still a Key Fixture in Wa...   \n",
      "9   AAPL  Could Buying Apple Stock Today Set You Up for ...   \n",
      "\n",
      "                 publisher            datetime  \\\n",
      "0             Watcher Guru 2024-12-01 08:00:00   \n",
      "1          The Motley Fool 2024-12-01 08:00:00   \n",
      "2               CryptoRank 2024-12-01 08:00:00   \n",
      "3          The Motley Fool 2024-11-30 08:00:00   \n",
      "4  The Acquirer's Multiple 2024-11-28 08:00:00   \n",
      "5            Yahoo Finance 2024-11-26 08:00:00   \n",
      "6            Yahoo Finance 2024-11-25 08:00:00   \n",
      "7            Yahoo Finance 2024-11-25 08:00:00   \n",
      "8            Yahoo Finance 2024-11-24 08:00:00   \n",
      "9          The Motley Fool 2024-11-23 08:00:00   \n",
      "\n",
      "                                                 url  \n",
      "0  https://news.google.com/rss/articles/CBMigAFBV...  \n",
      "1  https://news.google.com/rss/articles/CBMimAFBV...  \n",
      "2  https://news.google.com/rss/articles/CBMikAFBV...  \n",
      "3  https://news.google.com/rss/articles/CBMimAFBV...  \n",
      "4  https://news.google.com/rss/articles/CBMimgFBV...  \n",
      "5  https://news.google.com/rss/articles/CBMihwFBV...  \n",
      "6  https://news.google.com/rss/articles/CBMihAFBV...  \n",
      "7  https://news.google.com/rss/articles/CBMif0FVX...  \n",
      "8  https://news.google.com/rss/articles/CBMiekFVX...  \n",
      "9  https://news.google.com/rss/articles/CBMimAFBV...  \n",
      "53\n"
     ]
    }
   ],
   "source": [
    "df_gnews = fetch_gnews(\"AAPL\", \"2024-11-01\", \"2024-12-01\")\n",
    "print(df_gnews.head(10))\n",
    "print(len(df_gnews))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b41c30b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def fetch_reddit_search(ticker, days=7, max_posts=200):\n",
    "    url = \"https://www.reddit.com/search.json\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    rows = []\n",
    "    after_date = datetime.utcnow() - timedelta(days=days)\n",
    "    after_timestamp = int(after_date.timestamp())\n",
    "\n",
    "    params = {\n",
    "        \"q\": f\"{ticker}\",\n",
    "        \"sort\": \"new\",\n",
    "        \"limit\": 100,   # Reddit max\n",
    "        \"t\": \"year\"     # allow older results but we will filter manually\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Reddit API blocked:\", response.status_code)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    for post in data[\"data\"][\"children\"]:\n",
    "        info = post[\"data\"]\n",
    "\n",
    "        ts = info.get(\"created_utc\")\n",
    "        if ts is None:\n",
    "            continue\n",
    "\n",
    "        dt = datetime.utcfromtimestamp(ts)\n",
    "\n",
    "        # filter by days\n",
    "        if dt < after_date:\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"ticker\": ticker,\n",
    "            \"subreddit\": info.get(\"subreddit\"),\n",
    "            \"title\": info.get(\"title\"),\n",
    "            \"text\": info.get(\"selftext\"),\n",
    "            \"datetime\": dt,\n",
    "            \"url\": \"https://reddit.com\" + info.get(\"permalink\"),\n",
    "            \"score\": info.get(\"score\")\n",
    "        })\n",
    "\n",
    "        if len(rows) >= max_posts:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "735a88b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit API blocked: 403\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_reddit = fetch_reddit_search(\"AAPL\", days=7, max_posts=50)\n",
    "print(df_reddit.head())\n",
    "print(len(df_reddit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e0f7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_rss(url, ticker):\n",
    "    feed = feedparser.parse(url)\n",
    "    rows = []\n",
    "\n",
    "    for entry in feed.entries:\n",
    "        title = entry.get(\"title\", \"\")\n",
    "        link = entry.get(\"link\", \"\")\n",
    "        published = entry.get(\"published\", \"\")\n",
    "\n",
    "        # Convert datetime safely\n",
    "        try:\n",
    "            dt = datetime(*entry.published_parsed[:6])\n",
    "        except:\n",
    "            dt = None\n",
    "\n",
    "        rows.append({\n",
    "            \"ticker\": ticker,\n",
    "            \"title\": title,\n",
    "            \"publisher\": url.split(\"//\")[1].split(\"/\")[0],  # domain name\n",
    "            \"datetime\": dt,\n",
    "            \"url\": link\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f60195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSS_FEEDS = [\n",
    "    \"https://www.cnbc.com/id/10001147/device/rss/rss.html\",          # CNBC Markets\n",
    "    \"https://www.reuters.com/finance/markets/rss\",                  # Reuters Markets\n",
    "    \"https://www.marketwatch.com/rss/topstories\",                   # MarketWatch\n",
    "    \"https://www.nasdaq.com/feed/rssoutbound?category=Stock-Market\",\n",
    "    \"https://feeds.a.dj.com/rss/RSSMarketsMain.xml\",                # WSJ Markets\n",
    "    \"https://finance.yahoo.com/rss/topstories\",                     # Yahoo RSS\n",
    "    \"https://www.investing.com/rss/news_25.rss\",                    # Investing.com\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f87bbe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_rss_news(ticker):\n",
    "    dfs = []\n",
    "    for feed in RSS_FEEDS:\n",
    "        try:\n",
    "            df = parse_rss(feed, ticker)\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(\"RSS Error:\", feed, e)\n",
    "\n",
    "    if len(dfs) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    df_all = df_all.dropna(subset=[\"title\"])\n",
    "    df_all[\"datetime\"] = pd.to_datetime(df_all[\"datetime\"], errors=\"coerce\")\n",
    "\n",
    "    return df_all.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "937da615",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_rss = \u001b[43mfetch_rss_news\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAAPL\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_rss.head(\u001b[32m10\u001b[39m))\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTotal RSS articles:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_rss))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mfetch_rss_news\u001b[39m\u001b[34m(ticker)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feed \u001b[38;5;129;01min\u001b[39;00m RSS_FEEDS:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m         df = \u001b[43mparse_rss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m         dfs.append(df)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mparse_rss\u001b[39m\u001b[34m(url, ticker)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_rss\u001b[39m(url, ticker):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     feed = \u001b[43mfeedparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     rows = []\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m feed.entries:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/site-packages/feedparser/api.py:216\u001b[39m, in \u001b[36mparse\u001b[39m\u001b[34m(url_file_stream_or_string, etag, modified, agent, referrer, handlers, request_headers, response_headers, resolve_relative_uris, sanitize_html)\u001b[39m\n\u001b[32m    208\u001b[39m result = FeedParserDict(\n\u001b[32m    209\u001b[39m     bozo=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    210\u001b[39m     entries=[],\n\u001b[32m    211\u001b[39m     feed=FeedParserDict(),\n\u001b[32m    212\u001b[39m     headers={},\n\u001b[32m    213\u001b[39m )\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     data = \u001b[43m_open_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_file_stream_or_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodified\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferrer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandlers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m urllib.error.URLError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    218\u001b[39m     result.update({\n\u001b[32m    219\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mbozo\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    220\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mbozo_exception\u001b[39m\u001b[33m'\u001b[39m: error,\n\u001b[32m    221\u001b[39m     })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/site-packages/feedparser/api.py:115\u001b[39m, in \u001b[36m_open_resource\u001b[39m\u001b[34m(url_file_stream_or_string, etag, modified, agent, referrer, handlers, request_headers, result)\u001b[39m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m url_file_stream_or_string.read()\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(url_file_stream_or_string, \u001b[38;5;28mstr\u001b[39m) \\\n\u001b[32m    114\u001b[39m    \u001b[38;5;129;01mand\u001b[39;00m urllib.parse.urlparse(url_file_stream_or_string)[\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttps\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mftp\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfeed\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_file_stream_or_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodified\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferrer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandlers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# try to open with native open function (if url_file_stream_or_string is a filename)\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/site-packages/feedparser/http.py:171\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, etag, modified, agent, referrer, handlers, request_headers, result)\u001b[39m\n\u001b[32m    169\u001b[39m opener = urllib.request.build_opener(*\u001b[38;5;28mtuple\u001b[39m(handlers + [_FeedURLHandler()]))\n\u001b[32m    170\u001b[39m opener.addheaders = []  \u001b[38;5;66;03m# RMK - must clear so we only send our custom User-Agent\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m f = \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m data = f.read()\n\u001b[32m    173\u001b[39m f.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/urllib/request.py:519\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    516\u001b[39m     req = meth(req)\n\u001b[32m    518\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    522\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/urllib/request.py:536\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    535\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/urllib/request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/urllib/request.py:1391\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/urllib/request.py:1352\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m   1351\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m-> \u001b[39m\u001b[32m1352\u001b[39m     r = \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1354\u001b[39m     h.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/http/client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/http/client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/http/client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rocky9/2024.09/CS373/lib/python3.11/ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df_rss = fetch_rss_news(\"AAPL\")\n",
    "print(df_rss.head(10))\n",
    "print(\"Total RSS articles:\", len(df_rss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e32f7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "def unify_news_sources(df_yahoo, df_google, df_rss):\n",
    "    # --- Combine all sources ---\n",
    "    df = pd.concat([df_yahoo, df_google, df_rss], ignore_index=True)\n",
    "    \n",
    "    # --- Remove rows with missing title ---\n",
    "    df = df.dropna(subset=[\"title\"]).reset_index(drop=True)\n",
    "\n",
    "    # --- Normalize title (remove punctuation / lowercase) ---\n",
    "    df[\"title_norm\"] = (\n",
    "        df[\"title\"]\n",
    "        .str.lower()\n",
    "        .str.replace(r\"[^a-z0-9 ]\", \"\", regex=True)\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "    # --- FIRST PASS DEDUP: exact match on normalized title ---\n",
    "    df = df.drop_duplicates(subset=[\"title_norm\"], keep=\"first\")\n",
    "\n",
    "    # --- SECOND PASS DEDUP: group by similar timestamps ---\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], errors=\"coerce\")\n",
    "\n",
    "    df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "    rows = []\n",
    "    last_title = None\n",
    "    last_time = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if last_title == row[\"title_norm\"] and last_time is not None:\n",
    "            if abs(row[\"datetime\"] - last_time) < timedelta(hours=1):\n",
    "                continue  # skip near-duplicate article\n",
    "\n",
    "        rows.append(row)\n",
    "        last_title = row[\"title_norm\"]\n",
    "        last_time = row[\"datetime\"]\n",
    "\n",
    "    df_clean = pd.DataFrame(rows).drop(columns=[\"title_norm\"]).reset_index(drop=True)\n",
    "    return df_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce83705b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ticker                                              title        publisher  \\\n",
      "0    AAPL  Apple (AAPL) Stock: Peter Thiel is Right: The ...    US News Money   \n",
      "1    AAPL  Is Apple Stock Really Worth $150? - US News Money    US News Money   \n",
      "2    AAPL  Apple (AAPL) Stock vs. Alphabet (GOOG) Stock: ...    US News Money   \n",
      "3    AAPL  Apple Stock Smashes Previous All-Time High For...        MacRumors   \n",
      "4    AAPL  Apple, Inc.'s 10.5% Dividend Increase Is Disap...  The Motley Fool   \n",
      "5    AAPL  Slide in AAPL stock price continues into 5th d...          9to5Mac   \n",
      "6    AAPL  How iPhone X TrueDepth Camera Could Boost Appl...    InvestorPlace   \n",
      "7    AAPL  Is Apple Ready for Another Stock Split in 2018...  The Motley Fool   \n",
      "8    AAPL  The iPhone 8 Is a Disappointment For Apple Inc...    US News Money   \n",
      "9    AAPL  Why 3 Value Experts Say Apple Stock Is Still A...           Forbes   \n",
      "10   AAPL  Apple Stock Soars on $100 Billion Buyback - US...    US News Money   \n",
      "11   AAPL  Apple (AAPL) Stock Remains A Buy Even At New H...    Yahoo Finance   \n",
      "12   AAPL  Better Buy: Apple (AAPL) vs. Amazon (AMZN) Sto...    Yahoo Finance   \n",
      "13   AAPL  Why Apple's Stock Is Ready to Rebound - Invest...     Investopedia   \n",
      "14   AAPL  Apple Stock Price Target Is Cut Again at Goldm...    Bloomberg.com   \n",
      "15   AAPL  5 Top Stock Trades for Wednesday: AAPL, MCD, S...    InvestorPlace   \n",
      "16   AAPL  Mega-Cap Tech Stocks Surge for Fifth Day; Micr...    Bloomberg.com   \n",
      "17   AAPL   Apple Stock Jumps 4% on Earnings - US News Money    US News Money   \n",
      "18   AAPL  Correction Time for Apple Stock (AAPL) and Lar...    See It Market   \n",
      "19   AAPL      Should Apple (AAPL) Split Its Stock? - Nasdaq           Nasdaq   \n",
      "\n",
      "              datetime                                                url  \\\n",
      "0  2017-01-30 08:00:00  https://news.google.com/rss/articles/CBMiuAFBV...   \n",
      "1  2017-02-14 08:00:00  https://news.google.com/rss/articles/CBMimwFBV...   \n",
      "2  2017-03-13 07:00:00  https://news.google.com/rss/articles/CBMiugFBV...   \n",
      "3  2017-03-17 07:00:00  https://news.google.com/rss/articles/CBMifEFVX...   \n",
      "4  2017-05-04 07:00:00  https://news.google.com/rss/articles/CBMinAFBV...   \n",
      "5  2017-06-16 07:00:00  https://news.google.com/rss/articles/CBMiZEFVX...   \n",
      "6  2017-10-03 07:00:00  https://news.google.com/rss/articles/CBMikAFBV...   \n",
      "7  2017-12-09 08:00:00  https://news.google.com/rss/articles/CBMimAFBV...   \n",
      "8  2018-01-17 08:00:00  https://news.google.com/rss/articles/CBMimAFBV...   \n",
      "9  2018-03-23 07:00:00  https://news.google.com/rss/articles/CBMizAFBV...   \n",
      "10 2018-05-01 07:00:00  https://news.google.com/rss/articles/CBMipAFBV...   \n",
      "11 2018-08-09 07:00:00  https://news.google.com/rss/articles/CBMif0FVX...   \n",
      "12 2018-08-24 07:00:00  https://news.google.com/rss/articles/CBMiekFVX...   \n",
      "13 2018-11-16 08:00:00  https://news.google.com/rss/articles/CBMic0FVX...   \n",
      "14 2018-11-20 08:00:00  https://news.google.com/rss/articles/CBMitgFBV...   \n",
      "15 2019-04-30 07:00:00  https://news.google.com/rss/articles/CBMiiAFBV...   \n",
      "16 2019-06-10 07:00:00  https://news.google.com/rss/articles/CBMisAFBV...   \n",
      "17 2019-07-30 07:00:00  https://news.google.com/rss/articles/CBMipAFBV...   \n",
      "18 2019-11-25 08:00:00  https://news.google.com/rss/articles/CBMilwFBV...   \n",
      "19 2020-01-06 08:00:00  https://news.google.com/rss/articles/CBMiggFBV...   \n",
      "\n",
      "    source       date  \n",
      "0   google 2017-01-30  \n",
      "1   google 2017-02-14  \n",
      "2   google 2017-03-13  \n",
      "3   google 2017-03-17  \n",
      "4   google 2017-05-04  \n",
      "5   google 2017-06-16  \n",
      "6   google 2017-10-03  \n",
      "7   google 2017-12-09  \n",
      "8   google 2018-01-17  \n",
      "9   google 2018-03-23  \n",
      "10  google 2018-05-01  \n",
      "11  google 2018-08-09  \n",
      "12  google 2018-08-24  \n",
      "13  google 2018-11-16  \n",
      "14  google 2018-11-20  \n",
      "15  google 2019-04-30  \n",
      "16  google 2019-06-10  \n",
      "17  google 2019-07-30  \n",
      "18  google 2019-11-25  \n",
      "19  google 2020-01-06  \n",
      "Total articles: 110\n"
     ]
    }
   ],
   "source": [
    "# --- Fetch news ---\n",
    "df_yahoo = fetch_yahoo_news_api(\"AAPL\", count=100)\n",
    "df_yahoo[\"source\"] = \"yahoo\"\n",
    "\n",
    "df_google = fetch_gnews(\n",
    "    \"AAPL\",\n",
    "    start_date=\"2016-01-01\",\n",
    "    end_date=\"2024-12-31\"\n",
    ")\n",
    "df_google[\"source\"] = \"google\"\n",
    "\n",
    "# --- Combine ONLY Yahoo + Google ---\n",
    "df_all = pd.concat([df_yahoo, df_google], ignore_index=True)\n",
    "\n",
    "# --- Basic cleaning ---\n",
    "df_all[\"datetime\"] = pd.to_datetime(df_all[\"datetime\"], errors=\"coerce\")\n",
    "df_all = df_all.dropna(subset=[\"datetime\", \"title\"])\n",
    "\n",
    "# --- Create daily key for LSTM alignment ---\n",
    "df_all[\"date\"] = df_all[\"datetime\"].dt.date\n",
    "df_all[\"date\"] = pd.to_datetime(df_all[\"date\"])\n",
    "\n",
    "# --- Sort ---\n",
    "df_all = df_all.sort_values([\"date\", \"datetime\"]).reset_index(drop=True)\n",
    "\n",
    "print(df_all.head(20))\n",
    "print(\"Total articles:\", len(df_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc0fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align to LSTM trading days\n",
    "market_df = pd.read_csv(\"sp500_features.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "aapl_trading_days = set(\n",
    "    market_df[market_df[\"ticker\"] == \"AAPL\"][\"date\"].unique()\n",
    ")\n",
    "\n",
    "df_all = df_all[df_all[\"date\"].isin(aapl_trading_days)]\n",
    "\n",
    "print(\"After alignment:\", len(df_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa78389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a5fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900bc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Clear ALL HF caches in HOME\n",
    "# -----------------------------\n",
    "home_paths = [\n",
    "    os.path.expanduser(\"~/.cache/huggingface\"),\n",
    "    os.path.expanduser(\"~/.cache/torch\"),\n",
    "    os.path.expanduser(\"~/.huggingface\"),\n",
    "    os.path.expanduser(\"~/.local/share/huggingface\"),\n",
    "]\n",
    "for p in home_paths:\n",
    "    if os.path.exists(p):\n",
    "        shutil.rmtree(p, ignore_errors=True)\n",
    "\n",
    "# -------------------------------------------\n",
    "# 2. Create scratch directory for HF caching\n",
    "# -------------------------------------------\n",
    "SCRATCH_CACHE = f\"/scratch/scholar/{os.environ['USER']}/hf_cache\"\n",
    "os.makedirs(SCRATCH_CACHE, exist_ok=True)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3. Set ALL important cache environment vars\n",
    "# -----------------------------------------\n",
    "os.environ[\"HF_HOME\"] = SCRATCH_CACHE\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = SCRATCH_CACHE\n",
    "os.environ[\"HF_HUB_CACHE\"] = SCRATCH_CACHE\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = SCRATCH_CACHE\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = SCRATCH_CACHE\n",
    "os.environ[\"XDG_CACHE_HOME\"] = SCRATCH_CACHE\n",
    "os.environ[\"XDG_DATA_HOME\"] = SCRATCH_CACHE\n",
    "\n",
    "print(\"Using cache directory:\", SCRATCH_CACHE)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4. TEST: load SMALL Qwen model (0.5B)\n",
    "# -----------------------------------------\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=SCRATCH_CACHE)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=SCRATCH_CACHE\n",
    ")\n",
    "\n",
    "print(\"SUCCESS: Model loaded without using HOME directory!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc2e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "EMBED_SYSTEM_PROMPT = \"\"\"\n",
    "You are a financial news embedding model. Your task is to convert financial text\n",
    "into a JSON object with EXACTLY 8 numeric features. Each value must be a float\n",
    "in the range [-1, 1].\n",
    "\n",
    "The 8 features are:\n",
    "1. polarity       (negative → positive sentiment)\n",
    "2. intensity      (strength of sentiment)\n",
    "3. relevance      (how directly it relates to TARGET_TICKER)\n",
    "4. short_term     (expected next-day price impact)\n",
    "5. long_term      (expected multi-week impact)\n",
    "6. volatility     (uncertainty implied by the text)\n",
    "7. novelty        (new vs repeated information)\n",
    "8. credibility    (rumor → fact-based)\n",
    "\n",
    "You MUST output only a JSON object with these 8 fields.\n",
    "\n",
    "--------------------------------------------------------\n",
    "FEW-SHOT EXAMPLES\n",
    "--------------------------------------------------------\n",
    "\n",
    "Example A:\n",
    "TEXT: \"Netflix subscriber growth slows as competition intensifies across streaming platforms.\"\n",
    "TARGET_TICKER: NFLX\n",
    "\n",
    "OUTPUT:\n",
    "{\n",
    "  \"polarity\": -0.50,\n",
    "  \"intensity\": 0.70,\n",
    "  \"relevance\": 0.95,\n",
    "  \"short_term\": -0.40,\n",
    "  \"long_term\": -0.20,\n",
    "  \"volatility\": 0.60,\n",
    "  \"novelty\": 0.55,\n",
    "  \"credibility\": 0.90\n",
    "}\n",
    "\n",
    "Example B:\n",
    "TEXT: \"Coca-Cola reports strong international sales and raises full-year outlook.\"\n",
    "TARGET_TICKER: KO\n",
    "\n",
    "OUTPUT:\n",
    "{\n",
    "  \"polarity\": 0.60,\n",
    "  \"intensity\": 0.55,\n",
    "  \"relevance\": 0.90,\n",
    "  \"short_term\": 0.35,\n",
    "  \"long_term\": 0.50,\n",
    "  \"volatility\": 0.20,\n",
    "  \"novelty\": 0.30,\n",
    "  \"credibility\": 0.95\n",
    "}\n",
    "\n",
    "Example C:\n",
    "TEXT: \"Boeing receives a major multi-billion dollar aircraft order from a Middle Eastern airline.\"\n",
    "TARGET_TICKER: BA\n",
    "\n",
    "OUTPUT:\n",
    "{\n",
    "  \"polarity\": 0.80,\n",
    "  \"intensity\": 0.85,\n",
    "  \"relevance\": 1.00,\n",
    "  \"short_term\": 0.70,\n",
    "  \"long_term\": 0.75,\n",
    "  \"volatility\": 0.40,\n",
    "  \"novelty\": 0.70,\n",
    "  \"credibility\": 0.95\n",
    "}\n",
    "\n",
    "Example D:\n",
    "TEXT: \"Meta Faces a global outage across Instagram and Facebook services.\"\n",
    "TARGET_TICKER: META\n",
    "\n",
    "OUTPUT:\n",
    "{\n",
    "  \"polarity\": -0.75,\n",
    "  \"intensity\": 0.80,\n",
    "  \"relevance\": 1.00,\n",
    "  \"short_term\": -0.60,\n",
    "  \"long_term\": -0.35,\n",
    "  \"volatility\": 0.85,\n",
    "  \"novelty\": 0.65,\n",
    "  \"credibility\": 0.90\n",
    "}\n",
    "\n",
    "Example E:\n",
    "TEXT: \"Oil prices rise as OPEC announces unexpected production cuts.\"\n",
    "TARGET_TICKER: XLE\n",
    "\n",
    "OUTPUT:\n",
    "{\n",
    "  \"polarity\": 0.30,\n",
    "  \"intensity\": 0.65,\n",
    "  \"relevance\": 0.85,\n",
    "  \"short_term\": 0.40,\n",
    "  \"long_term\": 0.25,\n",
    "  \"volatility\": 0.70,\n",
    "  \"novelty\": 0.50,\n",
    "  \"credibility\": 0.95\n",
    "}\n",
    "\n",
    "--------------------------------------------------------\n",
    "\n",
    "NOW PROCESS THE NEW INPUT.\n",
    "Return ONLY the JSON object.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_embedding(text, ticker=\"AAPL\"):\n",
    "    user_prompt = f\"\"\"\n",
    "TARGET_TICKER: {ticker}\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\n",
    "Return ONLY the JSON object with the 8 fields.\n",
    "\"\"\"\n",
    "\n",
    "    prompt = f\"<|system|>\\n{EMBED_SYSTEM_PROMPT}\\n<|user|>\\n{user_prompt}\\n<|assistant|>\\n\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=300,\n",
    "        temperature=0.0,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # extract ALL JSON objects\n",
    "    matches = re.findall(r\"\\{.*?\\}\", decoded, flags=re.DOTALL)\n",
    "\n",
    "    if not matches:\n",
    "        print(\"No JSON found:\\n\", decoded)\n",
    "        return None\n",
    "\n",
    "    # use the LAST JSON (assistant output)\n",
    "    json_str = matches[-1]\n",
    "\n",
    "    try:\n",
    "        obj = json.loads(json_str)\n",
    "\n",
    "        vector = [\n",
    "            obj[\"polarity\"],\n",
    "            obj[\"intensity\"],\n",
    "            obj[\"relevance\"],\n",
    "            obj[\"short_term\"],\n",
    "            obj[\"long_term\"],\n",
    "            obj[\"volatility\"],\n",
    "            obj[\"novelty\"],\n",
    "            obj[\"credibility\"]\n",
    "        ]\n",
    "\n",
    "        return vector\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"JSON parse error:\", e)\n",
    "        print(\"Raw JSON:\", json_str)\n",
    "        print(\"Full Output:\", decoded)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1154f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def embed_all_articles(df):\n",
    "    vectors = []\n",
    "    for text in df[\"title\"]:\n",
    "        v = generate_embedding(text)\n",
    "        vectors.append(v)\n",
    "    df[\"embedding\"] = vectors\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfcd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def build_faiss_index(df):\n",
    "    # Convert to float32 matrix\n",
    "    embeds = np.vstack(df[\"embedding\"].values).astype(\"float32\")\n",
    "\n",
    "    index = faiss.IndexFlatL2(embeds.shape[1])   # 8 dims\n",
    "    index.add(embeds)\n",
    "\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e292c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_daily_query_embedding(ticker, date):\n",
    "    query_text = f\"{ticker} relevant financial news for {date}\"\n",
    "    return np.array(generate_embedding(query_text), dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b2e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_k(df, index, query_vec, k=3):\n",
    "    query_vec = query_vec.reshape(1, -1)\n",
    "    D, I = index.search(query_vec, k)\n",
    "    return df.iloc[I[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_daily(df_daily):\n",
    "    arr = np.vstack(df_daily[\"embedding\"].values)\n",
    "    return arr.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_news_embeddings(df, ticker, k=3):\n",
    "    df[\"date\"] = df[\"datetime\"].dt.date\n",
    "    index = build_faiss_index(df)\n",
    "\n",
    "    daily_vectors = []\n",
    "\n",
    "    for date in sorted(df[\"date\"].unique()):\n",
    "        query_vec = make_daily_query_embedding(ticker, date)\n",
    "        top_df = retrieve_top_k(df, index, query_vec, k=k)\n",
    "\n",
    "        agg_vec = aggregate_daily(top_df)\n",
    "        daily_vectors.append((date, agg_vec))\n",
    "\n",
    "    return daily_vectors\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS373",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
